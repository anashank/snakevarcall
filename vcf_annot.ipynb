{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Replace < > with appropriate file names/ folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfile_metadata = pd.read_excel(\"<Path to TCGA data file with file IDs>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = bamfile_metadata['File ID']\n",
    "sample_ids = {}\n",
    "count = 0\n",
    "for f in fileids:\n",
    "    row = bamfile_metadata.loc[bamfile_metadata['File ID'] == f]\n",
    "    sample_ids[f] = row['Sample ID'][count] \n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2520\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "all_files = glob.glob(\"<path to filtered SNP vcf files>\")\n",
    "indel_files = glob.glob(\"<path to filtered indel vcf files>\")\n",
    "\n",
    "all_files.extend(indel_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"<path to *.list file containing all variants>\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            if not(line.startswith('#')):\n",
    "                variant = line.strip().split(\"\\t\")\n",
    "                chrom = variant[0]\n",
    "                pos = variant[1]\n",
    "                ref = variant[3]\n",
    "                alt = variant[4]\n",
    "                f = variant[-1].split(\":\")\n",
    "                vcf_file = file.strip().split('/')\n",
    "                file_id = vcf_file[2].split('_')\n",
    "                sample_id = sample_ids[file_id[1]]\n",
    "                freq = f[6]\n",
    "                row = [chrom,pos,ref,alt,freq,sample_id]\n",
    "                row_list.append(row)\n",
    "            \n",
    "var_df = pd.DataFrame(row_list)\n",
    "var_df.columns = ['chr','pos','ref','alt','freq','sample_id']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To store variant allele frequencies corresponding to each sample \n",
    "allele_freq = {}\n",
    "\n",
    "for r in range(len(var_df)):\n",
    "    row = var_df.iloc[r]\n",
    "    key_list = [row['chr'],row['pos'],row['ref'],row['alt']]\n",
    "    key = \"-\".join(key_list)\n",
    "    if key not in allele_freq:\n",
    "        allele_freq[key] = []\n",
    "        allele_freq[key].append((row['sample_id'],row['freq']))\n",
    "    else:\n",
    "        allele_freq[key].append((row['sample_id'],row['freq']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = list(set(sample_ids.values())))\n",
    "final_df.insert(0,'variant',allele_freq.keys())\n",
    "for i,var in enumerate(allele_freq):\n",
    "    for id_freq in allele_freq[var]:\n",
    "        final_df.at[i, id_freq[0]] = id_freq[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['Chr','Pos','Ref','Alt']] = final_df.variant.str.split(pat='-',expand=True)\n",
    "cols = final_df.columns.tolist()\n",
    "new_cols = cols[-4:] + cols[1:len(cols)-4]\n",
    "final_df = final_df[new_cols]\n",
    "final_df = final_df.fillna('')\n",
    "\n",
    "final_df.sort_values(by=['Pos'],inplace=True)\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "final_df.to_excel(\"<path to variants excel file>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scripts to run to generate vcf file with unique variants\n",
    "\n",
    "'''\n",
    "Install picard tools and run the following command\n",
    "\n",
    "java -jar picard.jar MergeVcfs \\\n",
    "          I=input_variant_files.list \\\n",
    "          O=output_variants.vcf.gz \\\n",
    "          D=chr11.dict\n",
    "\n",
    "Install vcflib and run vcfstreamsort on output vcf file, followed by vcfuniq\n",
    "\n",
    "Link to repository for details: https://github.com/vcflib/vcflib\n",
    "'''\n",
    "\n",
    "row_list = []\n",
    "with open('<path to vcf file with unique variants>') as f:\n",
    "    for line in f:\n",
    "        if not(line.startswith('#')):\n",
    "            variant = line.strip().split(\"\\t\")\n",
    "            chrom = variant[0]\n",
    "            pos = variant[1]\n",
    "            ref = variant[3]\n",
    "            alt = variant[4]\n",
    "            row = [chrom,pos,ref,alt]\n",
    "            row_list.append(row)\n",
    "ann_df = pd.DataFrame(row_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run script to annotate vcf file using snpEff \n",
    "\n",
    "Link to snEff package: https://pcingola.github.io/SnpEff/\n",
    "\n",
    "java -Xmx4g -jar snpEff/snpEff.jar hg38 ---vcf file name--- > ---annotated vcf file name---\n",
    "'''\n",
    "cf_data = pd.read_csv('<path to annotated vcf file>',sep='\\t',comment='#',header=None)\n",
    "vcf_data.columns = ['chr','pos','1','ref','alt','2','filter','info','extra','values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = vcf_data['info'].str.split(';',expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_final = info[5].str.split('|',expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = info_final[[1,3,8,9,10]]\n",
    "to_add.columns = ['sequence ontology','gene name','exon rank/number','HGVS.p','AA change']\n",
    "to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data = pd.read_excel('<path to variants excel file>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data_new = pd.concat([var_data, to_add], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data_new.to_excel('<path to final variants excel file>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
